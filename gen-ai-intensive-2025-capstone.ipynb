{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Real-Time Financial Sentiment Classification using GenAI + RAG + Agent\n",
    "\n",
    "This capstone demonstrates an end-to-end **Generative AI pipeline** using **Gemini 2.0 Flash**, **retrieval-augmented generation (RAG)**, and a **LangChain Python agent** for financial sentiment analysis.\n",
    "\n",
    "The steps are:\n",
    "- Fetch **1000 real-time finance news articles**\n",
    "- Use **Gemini embeddings** to retrieve similar examples from a labeled dataset via **FAISS**\n",
    "- Build **few-shot prompts** dynamically and classify sentiment using Gemini Flash\n",
    "- Return a structured **JSON output** per article, showing the prediction and the supporting example\n",
    "\n",
    "**Impact**: This solution supports analysts and decision-makers by transforming unstructured market news into structured, explainable sentiment summaries in real time.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install Dependencies\n",
    "Install required libraries such as LangChain, Gemini SDK, FAISS, and sentence-transformers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "\n",
    "import os\n",
    "# for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    # for filename in filenames:\n",
    "        # print(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install dependencies in Kaggle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Up Gemini & Import Packages\n",
    "Configure the Gemini SDK and import all required Python packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q langchain faiss-cpu google-generativeai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U langchain-google-genai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LangChain + Gemini Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import google.generativeai as genai\n",
    "from langchain_core.tools import tool\n",
    "from langchain.agents import AgentExecutor, create_tool_calling_agent\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_core.tools import tool\n",
    "\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import faiss\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from typing import List\n",
    "from typing import Dict,Any\n",
    "import requests\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "GOOGLE_API_KEY = os.getenv(\"GOOGLE_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google import genai\n",
    "\n",
    "client = genai.Client(api_key=GOOGLE_API_KEY)\n",
    "import google.generativeai as genai\n",
    "\n",
    "model = genai.GenerativeModel('gemini-2.0-flash')\n",
    "def classify_with_gemini(prompt: str):\n",
    "    response = genai.generate_content(prompt, model=\"gemini-2.0-flash\")\n",
    "    return response.text.strip()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load & Clean Labeled Data\n",
    "Load the labeled financial sentiment dataset and prepare it for embedding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"all-data.csv\", encoding=\"ISO-8859-1\", header=None)\n",
    "df.columns = ['label', 'text']\n",
    "df['label'] = df['label'].str.lower().str.strip()\n",
    "df = df.iloc[:100,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embed Labeled Data with Gemini\n",
    "Use Gemini's embedding API to encode each labeled example for similarity search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 100/100 [01:32<00:00,  1.08it/s]\n"
     ]
    }
   ],
   "source": [
    "from google.generativeai import embed_content\n",
    "\n",
    "def get_gemini_embedding(text):\n",
    "    try:\n",
    "        response = client.models.embed_content(\n",
    "                model=\"models/text-embedding-004\",\n",
    "                contents=text,\n",
    "                config={\"task_type\":'RETRIEVAL_DOCUMENT'}\n",
    "        )\n",
    "        time.sleep(0.7)\n",
    "        return response.embeddings\n",
    "    except Exception as e:\n",
    "        print(\"Embedding failed:\", e)\n",
    "        return None\n",
    "\n",
    "# Step 5: Apply to the labeled dataset\n",
    "labeled_data = []\n",
    "for i, row in tqdm(df.iterrows(), total=len(df)):\n",
    "    embedding = get_gemini_embedding(row['text'])\n",
    "    if embedding:\n",
    "        labeled_data.append({\n",
    "            'text': row['text'],\n",
    "            'label': row['label'],\n",
    "            'embedding': embedding\n",
    "        })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build FAISS Index on Labeled Embeddings\n",
    "Use FAISS to index all labeled data vectors for fast nearest-neighbor retrieval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "label_embeddings = np.array([item['embedding'][0].values for item in labeled_data]).astype('float32')\n",
    "faiss.normalize_L2(label_embeddings)\n",
    "faiss_index = faiss.IndexFlatIP(label_embeddings.shape[1])\n",
    "faiss_index.add(label_embeddings)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fetch Real-Time Finance News\n",
    "Use NewsAPI to retrieve the top 100 recent finance-related news articles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "NEWS_API_KEY = os.getenv(\"NEWS_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool(parse_docstring=True)\n",
    "def fetch_news(query: str, max_results: int = 100) -> List[str]:\n",
    "    \"\"\"\n",
    "    Fetches recent English-language news articles matching the provided search query using the NewsAPI.\n",
    "\n",
    "    Args:\n",
    "        query (str): The search term or keywords to look for in news articles.\n",
    "        max_results (int, optional): The maximum number of articles to retrieve. Defaults to 100.\n",
    "\n",
    "    Returns:\n",
    "        List[str]: A list of strings, where each string contains the title and description of a news article.\n",
    "                   Returns an empty list if the request fails or no articles are found.\n",
    "\n",
    "    Example:\n",
    "        articles = fetch_news(\"artificial intelligence\", max_results=10)\n",
    "        # Returns a list of up to 10 news articles about artificial intelligence.\n",
    "    \"\"\"\n",
    "    url = \"https://newsapi.org/v2/everything\"\n",
    "    params = {\n",
    "        \"q\": query,\n",
    "        \"language\": \"en\",\n",
    "        \"pageSize\": max_results,\n",
    "        \"sortBy\": \"relevance\",\n",
    "        \"apiKey\": NEWS_API_KEY\n",
    "    }\n",
    "    response = requests.get(url, params=params)\n",
    "    if response.status_code != 200:\n",
    "        print(\"Failed to fetch news:\", response.text)\n",
    "        return []\n",
    "    return [f\"{a['title']}. {a['description']}\" for a in response.json().get(\"articles\", []) if a['description']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'description': 'Fetches recent English-language news articles matching the provided search query using the NewsAPI.',\n",
       " 'properties': {'query': {'description': 'The search term or keywords to look for in news articles.',\n",
       "   'title': 'Query',\n",
       "   'type': 'string'},\n",
       "  'max_results': {'default': 100,\n",
       "   'description': 'The maximum number of articles to retrieve. Defaults to 100.',\n",
       "   'title': 'Max Results',\n",
       "   'type': 'integer'}},\n",
       " 'required': ['query'],\n",
       " 'title': 'fetch_news',\n",
       " 'type': 'object'}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fetch_news.args_schema.model_json_schema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define LangChain Tool: RAG Retriever\n",
    "Wrap the retrieval function as a LangChain-compatible Tool for the agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool(parse_docstring=True)\n",
    "def retrieve_similar_labeled_example(news_text: str) -> Dict[str, str]:\n",
    "    \"\"\"\n",
    "    Finds and returns the most similar labeled financial example to the given news article using FAISS-based semantic search.\n",
    "\n",
    "    Args:\n",
    "        news_text (str): The news article or headline text to search for similar labeled examples.\n",
    "\n",
    "    Returns:\n",
    "        Dict[str, str]: A dictionary containing the following keys:\n",
    "            - 'example_text': The text of the most similar labeled finance example from the database.\n",
    "            - 'example_label': The label or category associated with the matched example.\n",
    "            - If embedding fails, returns {'error': 'Failed to embed'}.\n",
    "\n",
    "    Example:\n",
    "        result = retrieve_similar_labeled_example(\"Apple stock surges after earnings report.\")\n",
    "        # Returns: {'example_text': 'Apple posts record quarterly revenue...', 'example_label': 'positive'}\n",
    "    \"\"\"\n",
    "    query_vec = get_gemini_embedding(news_text)\n",
    "   \n",
    "    if query_vec is None:\n",
    "        return {\"error\": \"Failed to embed\"}\n",
    "    query_array = np.array(query_vec[0].values, dtype='float32').reshape(1, -1)\n",
    "    # print(query_array)\n",
    "    faiss.normalize_L2(query_array)\n",
    "    _, indices = faiss_index.search(query_array.reshape(1, -1), 1)\n",
    "    matched = labeled_data[indices[0][0]]\n",
    "    \n",
    "    return {\"example_text\": matched['text'], \"example_label\": matched['label']}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define LangChain Tool: Sentiment Classifier\n",
    "Wrap the few-shot Gemini classifier as another LangChain Tool."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### -Tool: Classify with Gemini (Few-shot prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool(parse_docstring=True)\n",
    "def classify_sentiment_with_few_shot(news: str, example_text: str, example_label: str) -> Dict[str, str]:\n",
    "    \"\"\"\n",
    "    Classifies the sentiment of a financial news article (positive, negative, or neutral) using a few-shot prompt with Gemini.\n",
    "    The function leverages a matched labeled example as in-context reference to improve classification accuracy.\n",
    "\n",
    "    Args:\n",
    "        news (str): The text of the financial news article to be classified.\n",
    "        example_text (str): A labeled example news text that is semantically similar to the input.\n",
    "        example_label (str): The sentiment label ('positive', 'negative', or 'neutral') of the example_text.\n",
    "\n",
    "    Returns:\n",
    "        Dict[str, str]: A dictionary containing:\n",
    "            - 'sentiment': The predicted sentiment for the input news article ('positive', 'negative', 'neutral', or 'unknown').\n",
    "            - 'news': The input news article text.\n",
    "            - 'example_text': The matched example news text used for few-shot prompting.\n",
    "            - 'example_label': The sentiment label of the matched example.\n",
    "            - If an error occurs, returns {'error': <error_message>}.\n",
    "\n",
    "    Example:\n",
    "        result = classify_sentiment_with_few_shot(\n",
    "            news=\"Tesla shares drop after recall announcement.\",\n",
    "            example_text=\"Tesla faces scrutiny after software glitch, stock falls.\",\n",
    "            example_label=\"negative\"\n",
    "        )\n",
    "        # Returns: {\n",
    "        #   'sentiment': 'negative',\n",
    "        #   'news': \"...\",\n",
    "        #   'example_text': \"...\",\n",
    "        #   'example_label': \"negative\"\n",
    "        # }\n",
    "    \"\"\"\n",
    "    prompt = f\"\"\"You are a financial sentiment classifier.\n",
    "    Here is an example:\n",
    "    Text: {example_text}\n",
    "    Sentiment: {example_label.capitalize()}\n",
    "    \n",
    "    Now classify the following:\n",
    "    Text: {news}\n",
    "    Sentiment:\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        response = client.models.generate_content(\n",
    "            model=\"gemini-2.0-flash\",\n",
    "            contents=prompt\n",
    "        )\n",
    "        sentiment = response.text.strip().lower()\n",
    "\n",
    "        if sentiment.startswith(\"positive\"):\n",
    "            sentiment = \"positive\"\n",
    "        elif sentiment.startswith(\"negative\"):\n",
    "            sentiment = \"negative\"\n",
    "        elif sentiment.startswith(\"neutral\"):\n",
    "            sentiment = \"neutral\"\n",
    "        else:\n",
    "            sentiment = \"unknown\"\n",
    "\n",
    "        return {\n",
    "            \"sentiment\": sentiment,\n",
    "            \"news\": news,\n",
    "            \"example_text\": example_text,\n",
    "            \"example_label\": example_label\n",
    "        }\n",
    "\n",
    "    except Exception as e:\n",
    "        return {\"error\": str(e)}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Agent and Run Over News Batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.language_models import BaseChatModel\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langchain_core.outputs import ChatResult, ChatGeneration\n",
    "from langchain.agents import initialize_agent, AgentType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Optional, Union, Any"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 🔁 Run Agent in Batch Mode\n",
    "Iterate through 1000 articles, retrieve examples, classify, and store the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 25/25 [02:40<00:00,  6.43s/it]\n"
     ]
    }
   ],
   "source": [
    "real_time_news = fetch_news(\"S&P 500 trend today\", max_results=100)\n",
    "\n",
    "results = []\n",
    "\n",
    "for article in tqdm(real_time_news[:25]):  # Test with 25 first\n",
    "    retrieved = retrieve_similar_labeled_example.run(article)\n",
    "    time.sleep(5) \n",
    "    if 'example_text' not in retrieved:\n",
    "        continue\n",
    "    \n",
    "    # Call classification with retrieved example\n",
    "    classification = classify_sentiment_with_few_shot.run({\n",
    "        \"news\":article,\n",
    "        \"example_text\":retrieved['example_text'],\n",
    "        'example_label':retrieved['example_label']\n",
    "})\n",
    "    \n",
    "    results.append(classification)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_time_news"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Structured Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-19T18:45:09.848321Z",
     "iopub.status.busy": "2025-05-19T18:45:09.847373Z",
     "iopub.status.idle": "2025-05-19T18:45:09.852295Z",
     "shell.execute_reply": "2025-05-19T18:45:09.851407Z",
     "shell.execute_reply.started": "2025-05-19T18:45:09.848293Z"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-19T18:42:36.872742Z",
     "iopub.status.busy": "2025-05-19T18:42:36.871986Z",
     "iopub.status.idle": "2025-05-19T18:42:36.878268Z",
     "shell.execute_reply": "2025-05-19T18:42:36.877393Z",
     "shell.execute_reply.started": "2025-05-19T18:42:36.872713Z"
    }
   },
   "outputs": [],
   "source": [
    "with open(\"financial_sentiment_results.json\", \"w\") as f:\n",
    "    json.dump(results, f, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-19T18:45:36.153181Z",
     "iopub.status.busy": "2025-05-19T18:45:36.152880Z",
     "iopub.status.idle": "2025-05-19T18:45:36.160764Z",
     "shell.execute_reply": "2025-05-19T18:45:36.159817Z",
     "shell.execute_reply.started": "2025-05-19T18:45:36.153163Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'example_label': 'negative',\n",
      "  'example_text': 'A tinyurl link takes users to a scamming site promising '\n",
      "                  'that users can earn thousands of dollars by becoming a '\n",
      "                  'Google ( NASDAQ : GOOG ) Cash advertiser .',\n",
      "  'news': \"Tech companies want humans to help level up AI models. What's your \"\n",
      "          'price for training them?. The humanization of AI is turning into a '\n",
      "          \"nice side hustle, and it's an interesting dilemma for the humans \"\n",
      "          'paid to train them.',\n",
      "  'sentiment': 'positive'},\n",
      " {'example_label': 'neutral',\n",
      "  'example_text': \"The broad-based WIG index ended Thursday 's session 0.1 pct \"\n",
      "                  'up at 65,003.34 pts , while the blue-chip WIG20 was 1.13 '\n",
      "                  'down at 3,687.15 pts .',\n",
      "  'news': 'Meta, Microsoft, Starbucks, Visa: Stocks to watch today. Markets '\n",
      "          'were slipping lower ahead of Wednesday’s open, with S&P 500 futures '\n",
      "          'down 0.7%, the Nasdaq down 1%, and the Dow Jones Industrial Average '\n",
      "          'off about 0.2%.Read more...',\n",
      "  'sentiment': 'negative'},\n",
      " {'example_label': 'positive',\n",
      "  'example_text': 'Shares of Standard Chartered ( STAN ) rose 1.2 % in the '\n",
      "                  'FTSE 100 , while Royal Bank of Scotland ( RBS ) shares rose '\n",
      "                  '2 % and Barclays shares ( BARC ) ( BCS ) were up 1.7 % .',\n",
      "  'news': 'Stock market today: Tech rally resumes as Nasdaq, S&P 500 lead '\n",
      "          'gains. US stocks gained after a mostly upbeat day on Wall Street, '\n",
      "          'driven by fresh signs President Trump is aiming to strike a trade '\n",
      "          'deal with China.',\n",
      "  'sentiment': 'positive'},\n",
      " {'example_label': 'positive',\n",
      "  'example_text': \"However , the broker gave an `` outperform '' \"\n",
      "                  'recommendation on the stock .',\n",
      "  'news': 'Market Volatility And Monday Morning Quarterbacks. Tech stocks led '\n",
      "          'Thursday’s rally, but market volatility remains high. Earnings show '\n",
      "          'forecasting challenges amid shifting supply chains. No clear trend; '\n",
      "          'risk management is key.',\n",
      "  'sentiment': 'negative'},\n",
      " {'example_label': 'neutral',\n",
      "  'example_text': \"The broad-based WIG index ended Thursday 's session 0.1 pct \"\n",
      "                  'up at 65,003.34 pts , while the blue-chip WIG20 was 1.13 '\n",
      "                  'down at 3,687.15 pts .',\n",
      "  'news': 'Stock market today: Dow, S&P 500, Nasdaq futures slide ahead of Fed '\n",
      "          'meeting as Trump hints at pharma tariffs. The countdown is on to '\n",
      "          \"the Fed's rate decision on Wednesday as policymakers begin their \"\n",
      "          'two-day meeting.',\n",
      "  'sentiment': 'negative'}]\n"
     ]
    }
   ],
   "source": [
    "with open(\"financial_sentiment_results.json\", \"r\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "pprint(data[:5])  "
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 622510,
     "sourceId": 1192499,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31012,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
