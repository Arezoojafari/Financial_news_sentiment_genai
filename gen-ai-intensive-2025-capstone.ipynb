{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Real-Time Financial Sentiment Classification using GenAI + RAG + Agent\n",
    "\n",
    "This capstone demonstrates an end-to-end **Generative AI pipeline** using **Gemini 2.0 Flash**, **retrieval-augmented generation (RAG)**, and a **LangChain Python agent** for financial sentiment analysis.\n",
    "\n",
    "The steps are:\n",
    "- Fetch **1000 real-time finance news articles**\n",
    "- Use **Gemini embeddings** to retrieve similar examples from a labeled dataset via **FAISS**\n",
    "- Build **few-shot prompts** dynamically and classify sentiment using Gemini Flash\n",
    "- Return a structured **JSON output** per article, showing the prediction and the supporting example\n",
    "\n",
    "**Impact**: This solution supports analysts and decision-makers by transforming unstructured market news into structured, explainable sentiment summaries in real time.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install Dependencies\n",
    "Install required libraries such as LangChain, Gemini SDK, FAISS, and sentence-transformers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-05-19T18:10:24.023629Z",
     "iopub.status.busy": "2025-05-19T18:10:24.023128Z",
     "iopub.status.idle": "2025-05-19T18:10:24.031393Z",
     "shell.execute_reply": "2025-05-19T18:10:24.030559Z",
     "shell.execute_reply.started": "2025-05-19T18:10:24.023600Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/sentiment-analysis-for-financial-news/all-data.csv\n",
      "/kaggle/input/sentiment-analysis-for-financial-news/FinancialPhraseBank/Sentences_66Agree.txt\n",
      "/kaggle/input/sentiment-analysis-for-financial-news/FinancialPhraseBank/Sentences_AllAgree.txt\n",
      "/kaggle/input/sentiment-analysis-for-financial-news/FinancialPhraseBank/README.txt\n",
      "/kaggle/input/sentiment-analysis-for-financial-news/FinancialPhraseBank/License.txt\n",
      "/kaggle/input/sentiment-analysis-for-financial-news/FinancialPhraseBank/Sentences_75Agree.txt\n",
      "/kaggle/input/sentiment-analysis-for-financial-news/FinancialPhraseBank/Sentences_50Agree.txt\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install dependencies in Kaggle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Up Gemini & Import Packages\n",
    "Configure the Gemini SDK and import all required Python packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-19T18:10:28.732024Z",
     "iopub.status.busy": "2025-05-19T18:10:28.731722Z",
     "iopub.status.idle": "2025-05-19T18:10:35.646628Z",
     "shell.execute_reply": "2025-05-19T18:10:35.645458Z",
     "shell.execute_reply.started": "2025-05-19T18:10:28.732003Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m31.3/31.3 MB\u001b[0m \u001b[31m46.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "!pip install -q langchain faiss-cpu google-generativeai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-19T18:10:35.648551Z",
     "iopub.status.busy": "2025-05-19T18:10:35.648198Z",
     "iopub.status.idle": "2025-05-19T18:10:42.657355Z",
     "shell.execute_reply": "2025-05-19T18:10:42.656494Z",
     "shell.execute_reply.started": "2025-05-19T18:10:35.648517Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m44.3/44.3 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m37.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m437.9/437.9 kB\u001b[0m \u001b[31m19.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "google-generativeai 0.8.4 requires google-ai-generativelanguage==0.6.15, but you have google-ai-generativelanguage 0.6.18 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install -q langchain-google-genai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LangChain + Gemini Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-19T18:10:42.659316Z",
     "iopub.status.busy": "2025-05-19T18:10:42.658971Z",
     "iopub.status.idle": "2025-05-19T18:10:46.885739Z",
     "shell.execute_reply": "2025-05-19T18:10:46.884807Z",
     "shell.execute_reply.started": "2025-05-19T18:10:42.659294Z"
    }
   },
   "outputs": [],
   "source": [
    "import google.generativeai as genai\n",
    "from langchain_core.tools import tool\n",
    "from langchain.agents import AgentExecutor, create_tool_calling_agent\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import faiss\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from typing import List\n",
    "from typing import Dict,Any\n",
    "import requests\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-19T18:10:47.553114Z",
     "iopub.status.busy": "2025-05-19T18:10:47.552401Z",
     "iopub.status.idle": "2025-05-19T18:10:47.739685Z",
     "shell.execute_reply": "2025-05-19T18:10:47.738884Z",
     "shell.execute_reply.started": "2025-05-19T18:10:47.553072Z"
    }
   },
   "outputs": [],
   "source": [
    "from kaggle_secrets import UserSecretsClient\n",
    "\n",
    "GOOGLE_API_KEY = UserSecretsClient().get_secret(\"GOOGLE_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-19T18:10:49.489163Z",
     "iopub.status.busy": "2025-05-19T18:10:49.488820Z",
     "iopub.status.idle": "2025-05-19T18:10:50.024555Z",
     "shell.execute_reply": "2025-05-19T18:10:50.023589Z",
     "shell.execute_reply.started": "2025-05-19T18:10:49.489133Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:623: UserWarning: <built-in function any> is not a Python type (it may be an instance of an object), Pydantic will allow any object with no validation since we cannot even enforce that the input is an instance of the given type. To get rid of this error wrap the type with `pydantic.SkipValidation`.\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "from google import genai\n",
    "\n",
    "client = genai.Client(api_key=GOOGLE_API_KEY)\n",
    "import google.generativeai as genai\n",
    "\n",
    "model = genai.GenerativeModel('gemini-2.0-flash')\n",
    "def classify_with_gemini(prompt: str):\n",
    "    response = genai.generate_content(prompt, model=\"gemini-2.0-flash\")\n",
    "    return response.text.strip()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load & Clean Labeled Data\n",
    "Load the labeled financial sentiment dataset and prepare it for embedding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-19T18:10:52.592130Z",
     "iopub.status.busy": "2025-05-19T18:10:52.591826Z",
     "iopub.status.idle": "2025-05-19T18:10:52.647562Z",
     "shell.execute_reply": "2025-05-19T18:10:52.646576Z",
     "shell.execute_reply.started": "2025-05-19T18:10:52.592107Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/kaggle/input/sentiment-analysis-for-financial-news/all-data.csv\", encoding=\"ISO-8859-1\", header=None)\n",
    "df.columns = ['label', 'text']\n",
    "df['label'] = df['label'].str.lower().str.strip()\n",
    "df = df.iloc[:1000,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embed Labeled Data with Gemini\n",
    "Use Gemini's embedding API to encode each labeled example for similarity search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-19T18:10:54.703078Z",
     "iopub.status.busy": "2025-05-19T18:10:54.702757Z",
     "iopub.status.idle": "2025-05-19T18:27:06.566363Z",
     "shell.execute_reply": "2025-05-19T18:27:06.565579Z",
     "shell.execute_reply.started": "2025-05-19T18:10:54.703055Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [16:11<00:00,  1.03it/s]\n"
     ]
    }
   ],
   "source": [
    "from google.generativeai import embed_content\n",
    "# from google.generativeai.types import EmbedContentConfig\n",
    "# Step 4: Function to embed text using Gemini\n",
    "def get_gemini_embedding(text):\n",
    "    try:\n",
    "        response = client.models.embed_content(\n",
    "            \n",
    "                model=\"models/text-embedding-004\",\n",
    "                contents=text,\n",
    "                config={\"task_type\":'RETRIEVAL_DOCUMENT'}\n",
    "                            \n",
    "        )\n",
    "        time.sleep(0.7)\n",
    "        return response.embeddings\n",
    "    except Exception as e:\n",
    "        print(\"Embedding failed:\", e)\n",
    "        return None\n",
    "\n",
    "# Step 5: Apply to the labeled dataset\n",
    "labeled_data = []\n",
    "for i, row in tqdm(df.iterrows(), total=len(df)):\n",
    "    embedding = get_gemini_embedding(row['text'])\n",
    "    if embedding:\n",
    "        labeled_data.append({\n",
    "            'text': row['text'],\n",
    "            'label': row['label'],\n",
    "            'embedding': embedding\n",
    "        })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build FAISS Index on Labeled Embeddings\n",
    "Use FAISS to index all labeled data vectors for fast nearest-neighbor retrieval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-19T18:29:15.178641Z",
     "iopub.status.busy": "2025-05-19T18:29:15.177876Z",
     "iopub.status.idle": "2025-05-19T18:29:15.236210Z",
     "shell.execute_reply": "2025-05-19T18:29:15.235447Z",
     "shell.execute_reply.started": "2025-05-19T18:29:15.178611Z"
    }
   },
   "outputs": [],
   "source": [
    "# Assume you already have labeled_data with 'text', 'label', and 'embedding'\n",
    "label_embeddings = np.array([item['embedding'][0].values for item in labeled_data]).astype('float32')\n",
    "faiss.normalize_L2(label_embeddings)\n",
    "faiss_index = faiss.IndexFlatIP(label_embeddings.shape[1])\n",
    "faiss_index.add(label_embeddings)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fetch Real-Time Finance News\n",
    "Use NewsAPI to retrieve the top 100 recent finance-related news articles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-19T18:29:17.043956Z",
     "iopub.status.busy": "2025-05-19T18:29:17.043666Z",
     "iopub.status.idle": "2025-05-19T18:29:17.217782Z",
     "shell.execute_reply": "2025-05-19T18:29:17.216798Z",
     "shell.execute_reply.started": "2025-05-19T18:29:17.043939Z"
    }
   },
   "outputs": [],
   "source": [
    "from kaggle_secrets import UserSecretsClient\n",
    "secrets = UserSecretsClient()\n",
    "NEWS_API_KEY = secrets.get_secret(\"NEWSAPI_KEY\")  # Or whatever name you used\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-19T18:29:19.021679Z",
     "iopub.status.busy": "2025-05-19T18:29:19.021334Z",
     "iopub.status.idle": "2025-05-19T18:29:19.027715Z",
     "shell.execute_reply": "2025-05-19T18:29:19.026936Z",
     "shell.execute_reply.started": "2025-05-19T18:29:19.021654Z"
    }
   },
   "outputs": [],
   "source": [
    "# Your existing NewsAPI fetch code\n",
    "def fetch_news(query: str, max_results: int = 100) -> List[str]:\n",
    "    url = \"https://newsapi.org/v2/everything\"\n",
    "    params = {\n",
    "        \"q\": query,\n",
    "        \"language\": \"en\",\n",
    "        \"pageSize\": max_results,\n",
    "        \"sortBy\": \"relevance\",\n",
    "        \"apiKey\": NEWS_API_KEY\n",
    "    }\n",
    "    response = requests.get(url, params=params)\n",
    "    if response.status_code != 200:\n",
    "        print(\"Failed to fetch news:\", response.text)\n",
    "        return []\n",
    "    return [f\"{a['title']}. {a['description']}\" for a in response.json().get(\"articles\", []) if a['description']]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define LangChain Tool: RAG Retriever\n",
    "Wrap the retrieval function as a LangChain-compatible Tool for the agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-19T18:29:21.440462Z",
     "iopub.status.busy": "2025-05-19T18:29:21.439819Z",
     "iopub.status.idle": "2025-05-19T18:29:21.450349Z",
     "shell.execute_reply": "2025-05-19T18:29:21.449416Z",
     "shell.execute_reply.started": "2025-05-19T18:29:21.440436Z"
    }
   },
   "outputs": [],
   "source": [
    "@tool\n",
    "def retrieve_similar_labeled_example(news_text: str) -> Dict[str, str]:\n",
    "    \"\"\"Retrieve the most similar labeled finance example to the input news article using FAISS.\"\"\"\n",
    "    query_vec = get_gemini_embedding(news_text)\n",
    "   \n",
    "    if query_vec is None:\n",
    "        return {\"error\": \"Failed to embed\"}\n",
    "    query_array = np.array(query_vec[0].values, dtype='float32').reshape(1, -1)\n",
    "    # print(query_array)\n",
    "    faiss.normalize_L2(query_array)\n",
    "    _, indices = faiss_index.search(query_array.reshape(1, -1), 1)\n",
    "    matched = labeled_data[indices[0][0]]\n",
    "    \n",
    "    return {\"example_text\": matched['text'], \"example_label\": matched['label']}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define LangChain Tool: Sentiment Classifier\n",
    "Wrap the few-shot Gemini classifier as another LangChain Tool."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### -Tool: Classify with Gemini (Few-shot prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-19T18:29:27.120274Z",
     "iopub.status.busy": "2025-05-19T18:29:27.119910Z",
     "iopub.status.idle": "2025-05-19T18:29:27.131539Z",
     "shell.execute_reply": "2025-05-19T18:29:27.130467Z",
     "shell.execute_reply.started": "2025-05-19T18:29:27.120247Z"
    }
   },
   "outputs": [],
   "source": [
    "from langchain.tools import tool\n",
    "\n",
    "@tool\n",
    "def classify_sentiment_with_few_shot(news: str, example_text: str, example_label: str) -> Dict[str, str]:\n",
    "    \"\"\"\n",
    "    Uses a few-shot prompt with Gemini to classify the sentiment (positive, negative, neutral)\n",
    "    of a financial news article based on a matched labeled example.\n",
    "    \"\"\"\n",
    "    prompt = f\"\"\"You are a financial sentiment classifier.\n",
    "Here is an example:\n",
    "Text: {example_text}\n",
    "Sentiment: {example_label.capitalize()}\n",
    "\n",
    "Now classify the following:\n",
    "Text: {news}\n",
    "Sentiment:\"\"\"\n",
    "\n",
    "    try:\n",
    "        response = client.models.generate_content(\n",
    "            model=\"gemini-2.0-flash\",\n",
    "            contents=prompt\n",
    "        )\n",
    "        sentiment = response.text.strip().lower()\n",
    "\n",
    "        if sentiment.startswith(\"positive\"):\n",
    "            sentiment = \"positive\"\n",
    "        elif sentiment.startswith(\"negative\"):\n",
    "            sentiment = \"negative\"\n",
    "        elif sentiment.startswith(\"neutral\"):\n",
    "            sentiment = \"neutral\"\n",
    "        else:\n",
    "            sentiment = \"unknown\"\n",
    "\n",
    "        return {\n",
    "            \"sentiment\": sentiment,\n",
    "            \"news\": news,\n",
    "            \"example_text\": example_text,\n",
    "            \"example_label\": example_label\n",
    "        }\n",
    "\n",
    "    except Exception as e:\n",
    "        return {\"error\": str(e)}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Agent and Run Over News Batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.language_models import BaseChatModel\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langchain_core.outputs import ChatResult, ChatGeneration\n",
    "from langchain.agents import initialize_agent, AgentType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-19T18:29:31.744960Z",
     "iopub.status.busy": "2025-05-19T18:29:31.744689Z",
     "iopub.status.idle": "2025-05-19T18:29:31.749170Z",
     "shell.execute_reply": "2025-05-19T18:29:31.748158Z",
     "shell.execute_reply.started": "2025-05-19T18:29:31.744942Z"
    }
   },
   "outputs": [],
   "source": [
    "from typing import List, Optional, Union, Any"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ” Run Agent in Batch Mode\n",
    "Iterate through 1000 articles, retrieve examples, classify, and store the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-19T18:29:34.139835Z",
     "iopub.status.busy": "2025-05-19T18:29:34.139489Z",
     "iopub.status.idle": "2025-05-19T18:32:12.389548Z",
     "shell.execute_reply": "2025-05-19T18:32:12.388534Z",
     "shell.execute_reply.started": "2025-05-19T18:29:34.139812Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [02:37<00:00,  6.30s/it]\n"
     ]
    }
   ],
   "source": [
    "real_time_news = fetch_news(\"S&P 500 trend today\", max_results=100)\n",
    "\n",
    "results = []\n",
    "\n",
    "for article in tqdm(real_time_news[:25]):  # Test with 25 first\n",
    "    retrieved = retrieve_similar_labeled_example.run(article)\n",
    "    time.sleep(5) \n",
    "    if 'example_text' not in retrieved:\n",
    "        continue\n",
    "    \n",
    "    # Call classification with retrieved example\n",
    "    classification = classify_sentiment_with_few_shot.run({\n",
    "        \"news\":article,\n",
    "        \"example_text\":retrieved['example_text'],\n",
    "        'example_label':retrieved['example_label']\n",
    "})\n",
    "    \n",
    "    results.append(classification)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Structured Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-19T18:45:09.848321Z",
     "iopub.status.busy": "2025-05-19T18:45:09.847373Z",
     "iopub.status.idle": "2025-05-19T18:45:09.852295Z",
     "shell.execute_reply": "2025-05-19T18:45:09.851407Z",
     "shell.execute_reply.started": "2025-05-19T18:45:09.848293Z"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-19T18:42:36.872742Z",
     "iopub.status.busy": "2025-05-19T18:42:36.871986Z",
     "iopub.status.idle": "2025-05-19T18:42:36.878268Z",
     "shell.execute_reply": "2025-05-19T18:42:36.877393Z",
     "shell.execute_reply.started": "2025-05-19T18:42:36.872713Z"
    }
   },
   "outputs": [],
   "source": [
    "with open(\"financial_sentiment_results.json\", \"w\") as f:\n",
    "    json.dump(results, f, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-19T18:45:36.153181Z",
     "iopub.status.busy": "2025-05-19T18:45:36.152880Z",
     "iopub.status.idle": "2025-05-19T18:45:36.160764Z",
     "shell.execute_reply": "2025-05-19T18:45:36.159817Z",
     "shell.execute_reply.started": "2025-05-19T18:45:36.153163Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'example_label': 'negative',\n",
      "  'example_text': 'A tinyurl link takes users to a scamming site promising '\n",
      "                  'that users can earn thousands of dollars by becoming a '\n",
      "                  'Google ( NASDAQ : GOOG ) Cash advertiser .',\n",
      "  'news': \"Tech companies want humans to help level up AI models. What's your \"\n",
      "          'price for training them?. The humanization of AI is turning into a '\n",
      "          \"nice side hustle, and it's an interesting dilemma for the humans \"\n",
      "          'paid to train them.',\n",
      "  'sentiment': 'positive'},\n",
      " {'example_label': 'neutral',\n",
      "  'example_text': \"The broad-based WIG index ended Thursday 's session 0.1 pct \"\n",
      "                  'up at 65,003.34 pts , while the blue-chip WIG20 was 1.13 '\n",
      "                  'down at 3,687.15 pts .',\n",
      "  'news': 'Meta, Microsoft, Starbucks, Visa: Stocks to watch today. Markets '\n",
      "          'were slipping lower ahead of Wednesdayâ€™s open, with S&P 500 futures '\n",
      "          'down 0.7%, the Nasdaq down 1%, and the Dow Jones Industrial Average '\n",
      "          'off about 0.2%.Read more...',\n",
      "  'sentiment': 'negative'},\n",
      " {'example_label': 'positive',\n",
      "  'example_text': 'Shares of Standard Chartered ( STAN ) rose 1.2 % in the '\n",
      "                  'FTSE 100 , while Royal Bank of Scotland ( RBS ) shares rose '\n",
      "                  '2 % and Barclays shares ( BARC ) ( BCS ) were up 1.7 % .',\n",
      "  'news': 'Stock market today: Tech rally resumes as Nasdaq, S&P 500 lead '\n",
      "          'gains. US stocks gained after a mostly upbeat day on Wall Street, '\n",
      "          'driven by fresh signs President Trump is aiming to strike a trade '\n",
      "          'deal with China.',\n",
      "  'sentiment': 'positive'},\n",
      " {'example_label': 'positive',\n",
      "  'example_text': \"However , the broker gave an `` outperform '' \"\n",
      "                  'recommendation on the stock .',\n",
      "  'news': 'Market Volatility And Monday Morning Quarterbacks. Tech stocks led '\n",
      "          'Thursdayâ€™s rally, but market volatility remains high. Earnings show '\n",
      "          'forecasting challenges amid shifting supply chains. No clear trend; '\n",
      "          'risk management is key.',\n",
      "  'sentiment': 'negative'},\n",
      " {'example_label': 'neutral',\n",
      "  'example_text': \"The broad-based WIG index ended Thursday 's session 0.1 pct \"\n",
      "                  'up at 65,003.34 pts , while the blue-chip WIG20 was 1.13 '\n",
      "                  'down at 3,687.15 pts .',\n",
      "  'news': 'Stock market today: Dow, S&P 500, Nasdaq futures slide ahead of Fed '\n",
      "          'meeting as Trump hints at pharma tariffs. The countdown is on to '\n",
      "          \"the Fed's rate decision on Wednesday as policymakers begin their \"\n",
      "          'two-day meeting.',\n",
      "  'sentiment': 'negative'}]\n"
     ]
    }
   ],
   "source": [
    "with open(\"financial_sentiment_results.json\", \"r\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "pprint(data[:5])  "
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 622510,
     "sourceId": 1192499,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31012,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
